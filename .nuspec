<?xml version="1.0"?>
<package>
  <metadata>
    <id>witsy</id>
    <version>3.5.1</version>
    <title>Witsy is a BYOK (Bring Your Own Keys) AI application</title>
    <authors>Nicolas Bonamy</authors>
    <owners>Mohammad Abu Mattar</owners>
    <licenseUrl>https://github.com/nbonamy/witsy/blob/main/LICENSE</licenseUrl>
    <projectUrl>https://witsyai.com/</projectUrl>
    <iconUrl>https://witsyai.com/img/logo.png</iconUrl>
    <requireLicenseAcceptance>false</requireLicenseAcceptance>
    <description><![CDATA[
# Witsy AI Chocolatey Package

## What is Witsy?

Witsy is a BYOK (Bring Your Own Keys) AI application: it means you need to have API keys for the LLM providers you want to use. Alternatively,
you can use [Ollama](https://ollama.com) to run models locally on your machine for free and use them in Witsy.

Non-exhaustive feature list:
- OpenAI, Ollama, Anthropic, MistralAI, Google, xAI, OpenRouter, DeepSeek, Groq and Cerebras models supported
- Connect other providers (together, siliconflow, fireworks...) through the OpenAI compatibility layer
- Chat completion with vision models support (describe an image)
- Text-to-image and text-to-video with OpenAI, HuggingFace, and Replicate
- Scratchpad to interactively create the best content with any model!
- Prompt anywhere allows to generate content directly in any application
- AI commands runnable on the highlighted text in almost any application
- Experts prompt you to specialize your bot on a specific topic
- LLM plugins to augment LLM: execute Python code, search the Internet...
- Long-term memory plugin to increase the relevance of LLM answers
- Read aloud assistant messages (requires OpenAI or ElevenLabs API key)
- Read aloud any text in other applications (requires OpenAI or ElevenLabs API key)
- Chat with your local files and documents (RAG)
- Transcription/Dictation (Speech-to-Text)
- Realtime Chat aka Voice Mode
- Anthropic Computer Use support
- Local history of conversations (with automatic titles)
- Formatting and copying to the clipboard-generated code
- Conversation PDF export
- Image copy and download

## Prompt Anywhere

Generate content in any application:
- From any editable content in any application
- Hit the Prompt anywhere shortcut (Shift+Control+Space / ^⇧Space)
- Enter your prompt in the window that pops up
- Watch Witsy enter the text directly in your application!

## AI Commands

AI commands are quick helpers accessible from a shortcut that leverages LLM to boost your productivity:
- Select any text in any application
- Hit the AI command shortcut (Alt+Control+Space / ⌃⌥Space)
- Select one of the commands and let LLM do their magic!

You can also create custom commands with the prompt of your liking!

![commands1](https://raw.githubusercontent.com/nbonamy/witsy/refs/heads/main/doc/commands1.jpg)
![commands2](https://raw.githubusercontent.com/nbonamy/witsy/refs/heads/main/doc/commands2.jpg)
![commands3](https://raw.githubusercontent.com/nbonamy/witsy/refs/heads/main/doc/commands3.jpg)

## Experts

From [https://github.com/f/awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts).

## Scratchpad

https://www.youtube.com/watch?v=czcSbG2H-wg

## Chat with your documents (RAG)

You can connect each chat with a document repository: Witsy will first search for relevant documents in your local files and provide this info to the LLM. To do so:

- Click on the database icon on the left of the prompt
- Click Manage and then create a document repository
- OpenAI Embedding requires an API key, and Ollama requires an embedding model
- Add documents by clicking the + button on the right-hand side of the window
- Once your document repository is created, click on the database icon once more and select the document repository you want to use. The icon should turn blue

## Transcription / Dictation (Speech-to-Text)

You can transcribe audio recorded on the microphone to text. Transcription can be done using the OpenAI Whisper online model (requires API key) or using the local Whisper model (requires download of large files). Once the text is transcribed you can:

- Copy it to your clipboard
- Insert it in the application that was running before you activated the dictation

## Anthropic Computer Use

https://www.youtube.com/watch?v=vixl7I07hBk
    ]]></description>
    <summary>Witsy: A flexible BYOK AI application for integrating various LLM providers or running models locally.</summary>
    <releaseNotes>https://github.com/nbonamy/witsy/releases/tag/v3.5.1</releaseNotes>
    <tags>witsy ai byok llm ollama</tags>
    <packageSourceUrl>https://github.com/MKAbuMattar/witsy-chocolatey-package</packageSourceUrl>
    <docsUrl>https://github.com/nbonamy/witsy/blob/main/README.md</docsUrl>
    <bugTrackerUrl>https://github.com/nbonamy/witsy/issues</bugTrackerUrl>
    <projectSourceUrl>https://github.com/nbonamy/witsy</projectSourceUrl>
  </metadata>
  <files>
    <file src="tools\**" target="tools" />
  </files>
</package>
